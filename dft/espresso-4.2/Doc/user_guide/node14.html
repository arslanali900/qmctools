<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>2.7 Installation tricks and problems</TITLE>
<META NAME="description" CONTENT="2.7 Installation tricks and problems">
<META NAME="keywords" CONTENT="user_guide">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="user_guide.css">

<LINK REL="previous" HREF="node13.html">
<LINK REL="up" HREF="node7.html">
<LINK REL="next" HREF="node15.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html470"
  HREF="node15.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.gif"></A> 
<A NAME="tex2html466"
  HREF="node7.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.gif"></A> 
<A NAME="tex2html462"
  HREF="node13.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.gif"></A> 
<A NAME="tex2html468"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html471"
  HREF="node15.html">3 Parallelism</A>
<B> Up:</B> <A NAME="tex2html467"
  HREF="node7.html">2 Installation</A>
<B> Previous:</B> <A NAME="tex2html463"
  HREF="node13.html">2.6 Running examples</A>
 &nbsp; <B>  <A NAME="tex2html469"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><A NAME="tex2html472"
  HREF="node14.html#SECTION00037100000000000000">2.7.1 All architectures</A>
<LI><A NAME="tex2html473"
  HREF="node14.html#SECTION00037200000000000000">2.7.2 Cray XT machines</A>
<LI><A NAME="tex2html474"
  HREF="node14.html#SECTION00037300000000000000">2.7.3 IBM AIX</A>
<LI><A NAME="tex2html475"
  HREF="node14.html#SECTION00037400000000000000">2.7.4 Linux PC</A>
<UL>
<LI><A NAME="tex2html476"
  HREF="node14.html#SECTION00037410000000000000">2.7.4.1 Linux PCs with Portland compiler (pgf90)</A>
<LI><A NAME="tex2html477"
  HREF="node14.html#SECTION00037420000000000000">2.7.4.2 Linux PCs with Pathscale compiler</A>
<LI><A NAME="tex2html478"
  HREF="node14.html#SECTION00037430000000000000">2.7.4.3 Linux PCs with gfortran</A>
<LI><A NAME="tex2html479"
  HREF="node14.html#SECTION00037440000000000000">2.7.4.4 Linux PCs with g95</A>
<LI><A NAME="tex2html480"
  HREF="node14.html#SECTION00037450000000000000">2.7.4.5 Linux PCs with Sun Studio compiler</A>
<LI><A NAME="tex2html481"
  HREF="node14.html#SECTION00037460000000000000">2.7.4.6 Linux PCs with AMD Open64 suite</A>
<LI><A NAME="tex2html482"
  HREF="node14.html#SECTION00037470000000000000">2.7.4.7 Linux PCs with Intel compiler (ifort)</A>
<LI><A NAME="tex2html483"
  HREF="node14.html#SECTION00037480000000000000">2.7.4.8 Linux PCs with MKL libraries</A>
<LI><A NAME="tex2html484"
  HREF="node14.html#SECTION00037490000000000000">2.7.4.9 Linux PCs with ACML libraries</A>
</UL>
<BR>
<LI><A NAME="tex2html485"
  HREF="node14.html#SECTION00037500000000000000">2.7.5 Linux PC clusters with MPI</A>
<LI><A NAME="tex2html486"
  HREF="node14.html#SECTION00037600000000000000">2.7.6 Intel Mac OS X</A>
<UL>
<LI><A NAME="tex2html487"
  HREF="node14.html#SECTION00037610000000000000">2.7.6.1 Intel Mac OS X with ifort</A>
<LI><A NAME="tex2html488"
  HREF="node14.html#SECTION00037620000000000000">2.7.6.2 Intel Mac OS X 10.4 with g95 and gfortran</A>
<LI><A NAME="tex2html489"
  HREF="node14.html#SECTION00037630000000000000">2.7.6.3 Intel Mac OS X 10.6</A>
</UL>
<BR>
<LI><A NAME="tex2html490"
  HREF="node14.html#SECTION00037700000000000000">2.7.7 SGI, Alpha</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H2><A NAME="SECTION00037000000000000000">
2.7 Installation tricks and problems</A>
</H2>

<P>

<H3><A NAME="SECTION00037100000000000000">
2.7.1 All architectures</A>
</H3>

<P>
Working Fortran-95 and C compilers are needed in order
to compile Q<SMALL>UANTUM </SMALL>ESPRESSO. Most ``Fortran-90'' compilers actually
implement the Fortran-95 standard, but older versions 
may not be Fortran-95 compliant. Moreover, 
C and Fortran compilers must be in your PATH.
If <TT>configure</TT> says that you have no working compiler, well,
you have no working compiler, at least not in your PATH, and
not among those recognized by <TT>configure</TT>.

<P>
If you get <EM>Compiler Internal Error</EM>' or similar messages: your
compiler version is buggy. Try to lower the optimization level, or to
remove optimization just for the routine that has problems. If it
doesn't work, or if you experience weird problems at run time, try to 
install patches for your version of the compiler (most vendors release
at least a few patches for free), or to upgrade to a more recent
compiler version.

<P>
If you get error messages at the loading phase that look like 
<EM>file XYZ.o: unknown / not recognized/ invalid / wrong
file type / file format / module version</EM>,
one of the following things have happened:

<OL>
<LI>you have leftover object files from a compilation with another
  compiler: run <TT>make clean</TT> and recompile. 
</LI>
<LI><TT>make</TT> did not stop at the first compilation error (it may 
happen in some software configurations). Remove the file *.o
that triggers the error message, recompile, look for a 
compilation error. 
</LI>
</OL>
If many symbols are missing in the loading phase: you did not specify the
location of all needed libraries (LAPACK, BLAS, FFTW, machine-specific
optimized libraries), in the needed order. 
If only symbols from <TT>clib/</TT> are missing, verify that
you have the correct C-to-Fortran bindings, defined in 
<TT>include/c_defs.h</TT>.
Note that Q<SMALL>UANTUM </SMALL>ESPRESSO is self-contained (with the exception of MPI libraries for 
parallel compilation): if system libraries are missing, the problem is in
your compiler/library combination or in their usage, not in Q<SMALL>UANTUM </SMALL>ESPRESSO.

<P>
If you get mysterious errors in the provided tests and examples:
your compiler, or your mathematical libraries, or MPI libraries,
or a combination thereof, is very likely buggy. Although the 
presence of subtle bugs in Q<SMALL>UANTUM </SMALL>ESPRESSO that are not revealed during 
the testing phase can never be ruled out, it is very unlikely
that this happens on the provided tests and examples. 

<P>

<H3><A NAME="SECTION00037200000000000000">
2.7.2 Cray XT machines</A>
</H3>

<P>
Use <TT>./configure ARCH=crayxt4</TT> or else <TT>configure</TT>will
not recognize the Cray-specific software environment. Older Cray 
machines: T3D, T3E, X1, are no longer supported.

<P>

<H3><A NAME="SECTION00037300000000000000">
2.7.3 IBM AIX</A>
</H3>
On IBM machines with ESSL libraries installed, there is a 
potential conflict between a few LAPACK routines that are also part of ESSL, 
but with a different calling sequence. The appearence of run-time errors like <EM>    ON ENTRY TO ZHPEV  PARAMETER NUMBER  1 HAD AN ILLEGAL VALUE</EM>
is a signal that you are calling the bad routine. If you have defined 
<TT>-D__ESSL</TT> you should load ESSL before LAPACK: see
variable LAPACK_LIBS in make.sys.

<P>

<H3><A NAME="SECTION00037400000000000000">
2.7.4 Linux PC</A>
</H3>

<P>
Both AMD and Intel CPUs, 32-bit and 64-bit, are supported and work,
either in 32-bit emulation and in 64-bit mode. 64-bit executables 
can address a much larger memory space than 32-bit executable, but
there is no gain in speed.
Beware: the default integer type for 64-bit machine is typically
32-bit long. You should be able to use 64-bit integers as well, 
but it will not give you any advantage and you may run into trouble.

<P>
Currently the following compilers are supported by <TT>configure</TT>:
Intel (ifort), Portland (pgf90), g95, gfortran, Pathscale (pathf95), 
Sun Studio (sunf95),  AMD Open64 (openf95). The ordering approximately
reflects the quality of support. Both Intel MKL and AMD acml mathematical
libraries are supported. Some combinations of compilers and of libraries
may however require manual editing of <TT>make.sys</TT>.

<P>
It is usually convenient to create semi-statically linked executables (with only
libc, libm, libpthread dynamically linked). If you want to produce a binary
that runs on different machines, compile it on the oldest machine you have
(i.e. the one with the oldest version of the operating system).

<P>
If you get errors like <EM>IPO Error: unresolved : __svml_cos2</EM>
at the linking stage, your compiler is optimized to use the SSE
version of sine, cosine etc. contained in the SVML library. Append
<TT>-lsvml</TT> to the list of libraries in your <TT>make.sys</TT> file (info by Axel
Kohlmeyer, oct.2007). 

<P>

<H4><A NAME="SECTION00037410000000000000">
2.7.4.1 Linux PCs with Portland compiler (pgf90)</A>
</H4>

<P>
Q<SMALL>UANTUM </SMALL>ESPRESSO does not work reliably, or not at all, with many old
versions (&lt; 6.1
<tex2html_verbatim_mark>) of the Portland Group compiler (pgf90).
 Use the latest version of each 
release of the compiler, with patches if available (see
the Portland Group web site, <TT>http://www.pgroup.com/</TT>).

<P>

<H4><A NAME="SECTION00037420000000000000">
2.7.4.2 Linux PCs with Pathscale compiler</A>
</H4>

<P>
Version 2.99 of the Pathscale EKO compiler (web site
<TT>http://www.pathscale.com/</TT>)
works and is recognized by
<TT>configure</TT>, but the preprocessing command, <TT>pathcc -E</TT>,
causes a mysterious error in compilation of iotk and should be replaced by
<PRE>
   /lib/cpp -P --traditional
</PRE>
The MVAPICH parallel environment with Pathscale compilers also works.
(info by Paolo Giannozzi, July 2008)

<P>

<H4><A NAME="SECTION00037430000000000000">
2.7.4.3 Linux PCs with gfortran</A>
</H4>

<P>
gfortran v.4.1.2 and later are supported. Earlier gfortran versions used to produce nonfunctional phonon executables (segmentation faults and the like), but more recent versions should be fine.

<P>
If you experience problems in reading files produced by previous versions
of Q<SMALL>UANTUM </SMALL>ESPRESSO: ``gfortran used 64-bit record markers to allow writing of records 
larger than 2 GB. Before with 32-bit record markers only records &lt;
<tex2html_verbatim_mark>2GB 
could be written. However, this caused problems with older files and 
inter-compiler operability. This was solved in GCC 4.2 by using 32-bit 
record markers but such that one can still store &gt;
<tex2html_verbatim_mark>2GB records (following 
the implementation of Intel). Thus this issue should be gone. See 4.2 
release notes (item ``Fortran") at 
<TT>http://gcc.gnu.org/gcc-4.2/changes.html</TT>."
(Info by Tobias Burnus, March 2010).

<P>
``Using gfortran v.4.4 (after May 27, 2009) and 4.5 (after May 5, 2009) can 
produce wrong results, unless the environment variable
GFORTRAN_UNBUFFERED_ALL=1 is set. Newer 4.4/4.5 versions
(later than April 2010) should be OK. See
<BR><TT>http://gcc.gnu.org/bugzilla/show_bug.cgi?id=43551</TT>."
(Info by Tobias Burnus, March 2010).

<P>

<H4><A NAME="SECTION00037440000000000000">
2.7.4.4 Linux PCs with g95</A>
</H4>

<P>
g95 v.0.91 and later (<TT>http://www.g95.org</TT>) works flawlessy. 
The executables it produces are however slower (let us say 20% or so) 
that those produced by gfortran, which in turn are slower 
(by another 20% or so) than those produced by ifort.

<P>

<H4><A NAME="SECTION00037450000000000000">
2.7.4.5 Linux PCs with Sun Studio compiler</A>
</H4>

<P>
``The Sun Studio compiler, sunf95, is free (web site:
<TT>http://developers.sun.com/sunstudio/</TT> and comes  
with a set of algebra libraries that can be used in place of the slow 
built-in libraries. It also supports openmp, which g95 does not. On the 
other hand, it is a pain to compile mpi with it. Furthermore the most
recent version has a terrible bug that totally miscompiles the iotk 
input/output library (you'll have to compile it with reduced optimization).''
(info by Lorenzo Paulatto, March 2010).

<P>

<H4><A NAME="SECTION00037460000000000000">
2.7.4.6 Linux PCs with AMD Open64 suite</A>
</H4>

<P>
The AMD Open64 compiler suite, openf95 (web site:
<TT>http://developer.amd.com/cpu/open64/pages/default.aspx</TT>)
can be freely downloaded from the AMD site.
It is recognized by <TT>configure</TT> but little tested. It sort of works 
but it fails to pass several tests.
(info by Paolo Giannozzi, March 2010).

<P>

<H4><A NAME="SECTION00037470000000000000">
2.7.4.7 Linux PCs with Intel compiler (ifort)</A>
</H4>

<P>
The Intel compiler, ifort, is available for  free for personal 
usage (<TT>http://software.intel.com/</TT>)  It seem to produce the faster executables, 
at least on Intel CPUs, but not all versions work as expected.
ifort versions &lt; 9.1
<tex2html_verbatim_mark> are not recommanded, due to the presence of subtle 
and insidious bugs. In case of trouble, update your version with 
the most recent patches,
available via Intel Premier support (registration free of charge for Linux):
<TT>http://software.intel.com/en-us/articles/intel-software-developer-support</TT>.

<P>
If <TT>configure</TT> doesn't find the compiler, or if you get 
<EM>Error loading shared libraries</EM> at run time, you may have 
forgotten to execute the script that
sets up the correct PATH and library path. Unless your system manager has
done this for you, you should execute the appropriate script - located in
the directory containing the compiler executable - in your
initialization files. Consult the documentation provided by Intel. 

<P>
The warning: <EM>feupdateenv is not implemented and will always fail</EM>, 
showing up in recent versions, can be safely ignored.
Since each major release of ifort
differs a lot from the previous one. compiled objects from different 
releases may be incompatible and should not be mixed.    

<P>
<B>ifort v.11</B>: Segmentation faults were reported for the combination 
ifort 11.0.081, MKL 10.1.1.019, openMP 1.3.3. The problem disappeared
with ifort 11.1.056 and MKL 10.2.2.025 (Carlo Nervi, Oct. 2009).

<P>
<B>ifort v.10:</B> on 64-bit AMD CPUs, at least some versions of ifort 10.1 
miscompile subroutine <TT>write_rho_xml</TT> in 
<TT>Module/xml_io_base.f90</TT> with -O2
optimization. Using -O1 instead solves the problem (info by Carlo
Cavazzoni, March 2008). 

<P>
"The intel compiler version 10.1.008 miscompiles a lot of codes (I have proof 
for CP2K and CPMD) and needs to be updated in any case" (info by Axel
Kohlmeter, May 2008).

<P>
<B>ifort v.9:</B> The latest (July 2006) 32-bit version of ifort 9.1
works flawlessy. Earlier versions yielded 
<EM>Compiler Internal Error</EM>.

<P>

<H4><A NAME="SECTION00037480000000000000">
2.7.4.8 Linux PCs with MKL libraries</A>
</H4>
On Intel CPUs it is very convenient to use Intel MKL libraries. They can be
also used for AMD CPU, selecting the appropriate machine-optimized
libraries, and also together with non-Intel compilers. Note however
that recent versions of MKL (10.2 and following) do not perform
well on AMD machines.

<P>
<TT>configure</TT> should recognize properly installed MKL libraries.
By default the non-threaded version of MKL is linked, unless option
<TT>configure -with-openmp</TT> is specified. In case of trouble,
refer to the following web page to find the correct way to link MKL:
<BR><TT>http://software.intel.com/en-us/articles/intel-mkl-link-line-advisor/</TT>.

<P>
MKL contains optimized FFT routines and a FFTW interface, to be separately
compiled. For 64-bit Intel Core2 processors, they are slightly faster than 
FFTW (MKL v.10, FFTW v.3 fortran interface, reported by P. Giannozzi,
November 2008). 

<P>
For parallel (MPI) execution on multiprocessor (SMP) machines, set the
environmental variable OMP_NUM_THREADS to 1 unless you know what you 
are doing. See Sec.<A HREF="node15.html#Sec:para">3</A> for more info on this
and on the difference between MPI and OpenMP parallelization. 

<P>

<H4><A NAME="SECTION00037490000000000000">
2.7.4.9 Linux PCs with ACML libraries</A>
</H4>
For AMD CPUs, especially recent ones, you may find convenient to 
link AMD acml libraries (can be freely downloaded from AMD web site). 
<TT>configure</TT> should recognize properly installed acml libraries,
together with the compilers most frequently used on AMD systems:
pgf90, pathscale, openf95, sunf95.

<P>

<H3><A NAME="SECTION00037500000000000000"></A>
<A NAME="SubSec:LinuxPCMPI"></A>
<BR>
2.7.5 Linux PC clusters with MPI
</H3>
PC clusters running some version of MPI are a very popular
computational platform nowadays. Q<SMALL>UANTUM </SMALL>ESPRESSO is known to work
with at least two of the major MPI implementations (MPICH, LAM-MPI),
plus with the newer MPICH2 and OpenMPI implementation. 
<TT>configure</TT> should automatically recognize a properly installed
parallel environment and prepare for parallel compilation. 
Unfortunately this not always happens. In fact:

<UL>
<LI><TT>configure</TT> tries to locate a parallel compiler in a logical
  place with a logical name,  but if it has a strange names or it is
  located  in a strange location, you will have to instruct <TT>configure</TT> 
  to find it. Note that in many PC clusters (Beowulf), there is no
  parallel Fortran-95 compiler in default installations:  you have to
  configure an appropriate script, such as mpif90. 
</LI>
<LI><TT>configure</TT> tries to locate libraries (both mathematical and
  parallel libraries) in the usual places with usual names, but if
  they have strange names or strange locations, you will have to
  rename/move them, or to instruct <TT>configure</TT> to find them. If MPI
  libraries are not found,
  parallel compilation is disabled. 
</LI>
<LI><TT>configure</TT> tests that the compiler and the libraries are
  compatible (i.e. the compiler may link the libraries without
  conflicts and without missing symbols). If they aren't and the
  compilation fail, <TT>configure</TT> will revert to serial compilation. 
</LI>
</UL>

<P>
Apart from such problems, Q<SMALL>UANTUM </SMALL>ESPRESSO compiles and works on all non-buggy, properly
configured hardware and software combinations. You may have to
recompile MPI libraries: not all MPI installations contain support for
the fortran-90 compiler of your choice (or for any fortran-90 compiler
at all!). Useful step-by-step instructions for MPI comilation can be 
found in the following post by  Javier Antonio Montoya:
<BR><TT>http://www.democritos.it/pipermail/pw_forum/2008April/008818.htm</TT>. 

<P>
If Q<SMALL>UANTUM </SMALL>ESPRESSO does not work for some reason on a PC cluster,
try first if it works in serial execution. A frequent problem with parallel
execution is that Q<SMALL>UANTUM </SMALL>ESPRESSO does not read from standard input,
due to the configuration of MPI libraries: see Sec.<A HREF="node17.html#SubSec:para">3.2</A>.

<P>
If you are dissatisfied with the performances in parallel execution,
see Sec.<A HREF="node15.html#Sec:para">3</A> and in particular Sec.<A HREF="node48.html#SubSec:badpara">9.4</A>.
See also the following post from Axel Kohlmeyer:
<BR><TT>http://www.democritos.it/pipermail/pw_forum/2008-April/008796.html</TT>

<P>

<H3><A NAME="SECTION00037600000000000000">
2.7.6 Intel Mac OS X</A>
</H3>

<P>
Newer Mac OS-X machines (10.4 and later) with Intel CPUs are supported 
by <TT>configure</TT>,
with gcc4+g95, gfortran, and the Intel compiler ifort with MKL libraries.
Parallel compilation with OpenMPI also works.

<P>

<H4><A NAME="SECTION00037610000000000000">
2.7.6.1 Intel Mac OS X with ifort</A>
</H4>

<P>
"Uninstall darwin ports, fink and developer tools. The presence of all of
those at the same time generates many spooky events in the compilation
procedure.  I installed just the developer tools from apple, the intel
fortran compiler and everything went on great" (Info by Riccardo Sabatini, 
Nov. 2007)

<P>

<H4><A NAME="SECTION00037620000000000000">
2.7.6.2 Intel Mac OS X 10.4 with g95 and gfortran</A>
</H4>

<P>
An updated version of Developer Tools (XCode 2.4.1 or 2.5), that can be 
downloaded from Apple, may be needed. Some tests fails with mysterious 
errors, that disappear if
fortran BLAS are linked instead of system Atlas libraries. Use: 
<PRE>
   BLAS_LIBS_SWITCH = internal
   BLAS_LIBS      = /path/to/espresso/BLAS/blas.a -latlas
</PRE>
(Info by Paolo Giannozzi, jan.2008, updated April 2010)

<P>

<H4><A NAME="SECTION00037630000000000000">
2.7.6.3 Intel Mac OS X 10.6</A>
</H4>

<P>
``I have performed some limited amount of tests, and everything seems to
be fine under macports supplied environment up to now. I have installed
using the following manner:''
<PRE>
   port install gcc43
   port install g95
</PRE>
(rename apple supplied mpi to something else)
<BR>(dowload and install openmpi )
<PRE>
  ./configure CC=gcc-mp-4.3 CPP=cpp-mp-4.3 CXX=g++-mp-4.3 F77=g95 FC=g95
</PRE>
(download and install Q<SMALL>UANTUM </SMALL>ESPRESSO)
<PRE>
  ./configure CC=gcc-mp-4.3 CPP=cpp-mp-4.3 CXX=g++-mp-4.3 F77=g95 FC=g95
</PRE>
(Info by Osman Baris Malcioglu, May 2010)

<P>

<H3><A NAME="SECTION00037700000000000000">
2.7.7 SGI, Alpha</A>
</H3>

<P>
SGI Mips machines (e.g. Origin) and HP-Compaq Alpha machines are
no longer supported since v.4.2.

<P>

<P>
<HR>
<!--Navigation Panel-->
<A NAME="tex2html470"
  HREF="node15.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.gif"></A> 
<A NAME="tex2html466"
  HREF="node7.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.gif"></A> 
<A NAME="tex2html462"
  HREF="node13.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.gif"></A> 
<A NAME="tex2html468"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.gif"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html471"
  HREF="node15.html">3 Parallelism</A>
<B> Up:</B> <A NAME="tex2html467"
  HREF="node7.html">2 Installation</A>
<B> Previous:</B> <A NAME="tex2html463"
  HREF="node13.html">2.6 Running examples</A>
 &nbsp; <B>  <A NAME="tex2html469"
  HREF="node1.html">Contents</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
Paolo Giannozzi
2010-05-07
</ADDRESS>
</BODY>
</HTML>
